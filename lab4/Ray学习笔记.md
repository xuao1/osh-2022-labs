### Ray 框架的需求和设计

#### 下一代 AI 应用的需求

下一代的 AI 应用将与环境存在连续的交互并从这些交互动作之中进行学习。这就是强化学习范式所描述的需求：在一个不确定的环境中，根据有限的、具有延迟的反馈来完成一系列动作，从而达到目标。

强化学习应用的核心目标是要学习一个策略，这个策略将环境的状态映射为动作的选择，久而久之智能体将学会一个有效的任务。在大规模的应用中，寻找有效的策略需要三大能力：

仿真：

分布式训练：在强化学习中，进行策略评估后还需要进行策略改进，其中使用的数据便来自仿真过程或与物理环境的交互

服务部署

#### 计算框架的系统需求

系统需求：

+ 支持细粒度的计算：单次计算非常轻量，但是所需计算的次数十分庞大
+ 支持对于时间和资源的非均匀使用
+ 支持动态执行

Ray 是一种通用的集群计算框架，既支持模型的训练，又支持对环境的仿真或与环境的交互，还支持模型服务。Ray 所面临的任务涵盖了从轻量级、无状态的计算任务（如仿真）到长时间运行的、有状态的计算任务（如训练）。

为了满足这些任务的需求，Ray 实现了一套统一的接口，这套接口既能变大基于任务的并行计算（task-parallel），又能表达基于行动器的并行计算（actor-based）。

为了满足性能需求，Ray使用了分布式的任务调度器和元数据存储器设计，从而满足了Ray的毫秒百万级并发量的需求。

服务是指利用策略根据状态来计算动作，仿真是指执行动作，产生状态转移和奖励，并记录轨迹的过程。服务和方针的过程统称为预演（Rollout），预演过程中策略不发生改变。



### Ray 编程设计

| 代码                                                         | 说明                                                         |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
| futures = f.remote(args)                                     | 远程地执行函数 f。f.remote() 以普通对象或 future 对象作为输入，返回一个或多个 future 对象，非阻塞执行。 |
| objects = ray.get(futures)                                   | 返回与一个或多个 future 对象相关联的真实值，阻塞执行         |
| ready_futures = ray.wait(futures, k, timeout)                | 当 futures 中有 k 个 future 完成时，或执行时间超过 timeout 时，返回 futures 中已经执行完的 future |
| actor = Class.remote(args) futures = actor.method.remote(args) | 将一个类实例化为一个远程的行动器，并返回它的一个句柄。然后调用这个行动器的 method 方法，并返回一个或多个 future. 两个过程均为非阻塞的。 |

Ray 中有两个重要的概念：任务（task）和行动器（actor）

#### 任务

任务是指在无状态的工作器中执行的远程函数。远程函数被调用时会立即返回一个 future 对象，而真正的返回值可以通过 ray.get(<future 对象 >) 的方式来获取。这样的编程模型既允许用户编写并行计算代码，同时又提醒用户要关注数据之间的依赖性。

**任务的编程范式**如下：

1. 注册任务：在需要注册为任务的函数上加上 @ray.remote 装饰器
2. 提交任务：在调用具有 @ray.remote 装饰器的函数时，需要带上 .remote() 而不是直接调用
3. 非阻塞提交：无论任务的运行需要多少时间，在提交任务后都会立即返回一个 ObjectRef 对象
4. 按需阻塞获取结果：在你需要函数的返回值时，可以通过 ray.get 来获取

任务是无状态的，任务所操作的对象都可以看作不可变对象 (Immutable Objects)，或者任务调用可以看作一个无副作用的 (Side-effect Free) 表达式，任务的输出（返回值）仅与输入（实参）有关。下面的代码展示了 Ray 远程函数（任务）总是无副作用的。

这样设计的优点是能在函数执行出错时自动重新执行函数（因为不依赖于其他任务，可以在任意时候独立地执行），以提高容错性

#### 行动器

行动器用来表达有状态的计算任务。每个行动器都会暴露一些可供远程调用的方法，类似于任务中的远程函数，不同的是，使用 f.remote 顺序地提交若干个远程函数后，这些函数是并行执行的，但在同一个 actor 下使用 actor.method.remote 顺序地提交若干个远程方法后，这些方法将串行地执行。但是，不同 actor 之间的调用是可以并行的。

行动器方法的调用可能会修改行动器的状态，而这一状态可能会影响后续方法的调用，因此同一行动器下的方法需要按照提交顺序串行地调用。

**行动器的编程范式**如下：

1. 注册行动器：在需要注册为行动器的类上加上 @ray.remote 装饰器
2. 实例化行动器：相比于普通 Python 类的实例化，需要在类名后加上 .remote
3. 提交方法调用：调用行动器的方法时，同样需要带上 .remote() 而不是直接调用
4. 非阻塞提交：无论方法的运行需要多少时间，在提交任务后都会立即返回一个 ObjectRef 对象（同一行动器实例下，方法会按照提交顺序串行地运行）
5. 按需阻塞获取结果：在需要方法运行的返回值时，可以通过 ray.get 来获取



### Ray 计算模型

Ray 采用**动态任务图计算模型**，在这一模型中，当输入数据就绪时，系统将自动触发相应的远程函数和行动器方法的执行。








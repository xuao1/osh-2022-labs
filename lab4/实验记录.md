## Ray

### 1. 特点

+ 提供一种能够构建、运行分布式应用程序的 simple primitives
+ 从单机扩展到平行，几乎不需要改代码
+ 拥有良好的生态，能够在 core Ray 上构建复杂的应用程序

### 2. 计算原语

+ Task：一个无状态的计算任务（函数表示），Ray 允许**异步执行任意函数**，这些 remote function （Task）的开销非常低，可以在毫秒内执行，并且可以自动向集群添加节点并调度任务，非常适合扩展计算密集型应用程序和服务。
+ Actor：一个有状态的计算任务（类表示），Actor 模型是一个强大的异步编程范例（支持微服务），可以在本地和远程无缝工作。Actor 本质上是一个有状态的 Worker（或 Service）。当一个新的 Actor 被实例化是，就创建一个新的 Worker，并将该 Actor 的方法调度到这个特定的 Worker，也可以对 Worker 的状态进行访问和修改

### 3. API

#### 3.1 ray.init()

描述：在应用程序中初始化 Ray

#### 3.2 @ray.remote

描述：如果用来修饰函数，则该函数变为一个远程 Task；如果用来修饰类，则该类变为一个远程 Actor

例子：

```python
@ray.remote                     # 定义一个Task
def train_model(source):
    ...

@ray.remote                     # 定义一个Actor
class ActivityTracker():
    def record(event):
        ...
        return count</code> 
```

#### 3.3 x.remote

描述：构造一个 Actor 实例，或是异步运行一个 Task 或 Actor 的方法

例子：

```python
m_id = train_model.remote(...)       # 调用一个Task

tracker = ActivityTracker.remote()   # 构造一个Actor实例
tr_id =  tracker.record.remote(...)  # 调用一个Actor方法
```

#### 3.4 ray.put()

描述：将一个值放入分布式对象存储中

例子：

```python
put_id = ray.put(my_object)
```

#### 3.5 ray.get()

描述：从分布式对象存储中获取一个对象，这个对象可以是由 `ray.put` 显式存入的，也可以是由 Task 或 Actor 方法存入的，这个方法会一直阻塞直到获取的对象可用

例子：

```python
model = ray.get(m_id)           # 获取train_model任务的结果
count = ray.get(tr_id)          # 获取tracker.record方法的返回结果 
thing = ray.get(put_id)         # 获取my_object
```

#### 3.6 ray.wait()

描述：返回已准备好的 ID 列表和尚未准备好的 ID 列表，第一个列表由对象引用组成，这些对象引用余对象存储中可用的对象相对应。第二个列表对应于其余的对象引用（可能已准备就绪，也可能尚未准备就绪）

例子：

```python
finished, running = ray.wait([m_id, tr_id])
```

### 4. The Core of Ray's Paper

#### 4.1 Introduction

Ray 实现了一个动态的任务图计算模型，可以提供任务的并行构象；同时还提供了一个 Actor 编程抽象，可以使能够支持有状态的组件

为了保证高性能，Ray 采用了可横向扩展的新型分布式体系结构。架构基于两个关键的想法：

+ 首先，将系统的所有控制状态存储在一个全局控制存储器中，这可以令所有的系统组件都是无状态的（stateless）。因此，每个组件都可以轻松地水平扩展，并在发生故障时重新启动。同时，全局控制存储可以通过共享进行扩展，并通过复制实现容错。
+ 其次，提出一种新的自下而上的分布式调度器，Worker 和驱动程序将 Task 提交给 local scheduler（每个节点有一个 local sheduler）。本地调度程序可以选择在本地对任务进行调度，也可以将任务转发到已备份的全局调度程序。以允许本地决策的方式来减少任务延迟，并且通过减轻全局调度器的负担来增加系统吞吐量。

#### 4.2 Motivation and Requirements

AI 应用程序的3大关键需求：灵活性、性能、易于并发

#### 4.3 Programming Model and API

Ray 的核心是提供一个任务并行编程模型、

+ 在调用 `remote()` 时，会返回一个对象的引用（future）以表示 Task 的结果，并使用 `ray.get()` 从对象的引用中获取远程对象 ref 放入本地对象存储中。
+ `ray.get()` 是阻塞的，不用使用没有执行完的 future。
+ `ray.wait()` 可以消除阻塞，在处理并发任务时，先处理已经执行好的任务。
+ Ray可以进行 `remote()` 的嵌套，即 `remote()` 函数可以调用其他的 `remote()`。这可以使多个进行并行调用 `remote()`，防止驱动程序将成为 task 调用的瓶颈，实现高可伸缩性。
+ Ray 使用 Actor 抽象来增强变成模型，将 API 从函数（task）扩展到类，Actor 本质上是一个有状态的 worker。
+ Actors 将 Ray API 从函数（task）扩展到类。Actor 本质上是一个有状态的 worker，每个 actor 也可以定义一些函数，提供远程调用

#### 4.4 Computation Model

Ray 通过利用动态任务图计算模型，来实现 remote function、actor 的调用

#### 4.5 Architecture

![image-20220630110759069](C:\Users\86198\AppData\Roaming\Typora\typora-user-images\image-20220630110759069.png)

##### 应用层由3部分组成：

+ Driver：执行用户程序的进程
+ Worker：执行由 Driver 或其他 Worker 调用的 task 的无状态进程。系统层自动启动 worker 并分配 Task，当声明 remote function 时，该 Task 会自动发布给所有 Worker。Worker 会连续执行 Task
+ Actor：一个有状态的进程，当它被调用时则执行类内部暴露的方法。与 Worker 不同，Actor 由 Worker 或 Driver 明确实例化。Actor 会连续执行方法

应用层面，用户在 Driver 定义的 Task，会同步推送到所有的 Worker 上去，Worker 会顺序的执行这些 Task。Worker 是没有状态的，因此不会在 Task 中保持 local state。在执行确定性 Task 时，在所有的 Worker 上调用参数相同的 remote function 都将返回相同的结果

##### 系统层由3部分组成

+ 全局控制存储区（GCS）：将所有最新的元数据和控制状态信息存储在系统中，通过这种集中存储统一控制的方式，GCS 使每个其他组件都成为无状态，可以轻松对每个其他组件进行横向扩展，在百万级别并发任务下提高负载和容错
+ 分布式调度程序：采用全局调度器和各节点本地调度器。节点上创建的 Task 优先提交给节点的本地调度程序。如果本地调度器不能完成 Task，则将所有 Task 转移到全局调度器，全局调度器接收到任务后，根据每个本地调度器发送的心跳决定将 Task 分配到不同的节点。如果全局调度器过载，则可以实例化更多副本，实现调度体系可扩展。
+ 分布式对象存储区：在每个节点上将每个对象保存在内存中，使 worker 和 actors 能够有效地共享数据。如果任务在同一节点上，则任务之间共享数据；人物的输出必须在本地内存读写数据，任务的输入如果不在本地的，则在执行之前将输入复制到同一节点上的本地对象存储。数据本地化的设计是提升计算效率的关键。

#### 4.6 Execution Process





## 参考文献

[AI时代的Spark：Ray，你值得拥有！ - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/399209343)















